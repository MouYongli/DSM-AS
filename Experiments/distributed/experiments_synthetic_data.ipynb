{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b658f34",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ddaf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import datetime\n",
    "import pytz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from fhirpy import SyncFHIRClient\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Flatten, Embedding, Multiply, Concatenate, Input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, Sequential\n",
    "# from keras.optimizers import adam_v2 # Error: cannot import name 'adam_v2' from 'keras.optimizers'\n",
    "from keras.optimizers import Adam\n",
    "import csv\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "fix_all_seeds(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8f2e3",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35244e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"./input/data.csv\")\n",
    "df_data = df_data.rename(columns={\"concave points_mean\":\"concave.points_mean\", \"concave points_se\": \"concave.points_se\", \"concave points_worst\":\"concave.points_worst\", \"diagnosis\":\"label\"})\n",
    "df_data = df_data.drop([\"Unnamed: 32\"], axis=1)\n",
    "\n",
    "station_list = [\"uka\", \"ukg\", \"ukk\", \"ukl\", \"imise\", \"mittweida\"]\n",
    "station_dfs = [pd.read_csv(\"./input/{}.csv\".format(station)).rename(columns={\"patient_id\":\"id\"}) for station in station_list]\n",
    "final_test_df = pd.read_csv(\"./input/final_test.csv\").rename(columns={\"patient_id\":\"id\"})\n",
    "for idx in range(len(station_list)):\n",
    "    station_dfs[idx][\"id\"] = station_dfs[idx][\"id\"].map(lambda x: int(x[6:]))\n",
    "    station_dfs[idx] = pd.merge(df_data, station_dfs[idx], on='id', how='right')\n",
    "final_test_df[\"id\"] = final_test_df[\"id\"].map(lambda x: int(x[6:]))\n",
    "final_test_df = pd.merge(df_data, final_test_df, on='id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d6d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "569\n",
      "228\n",
      "[56, 56, 56, 56, 61, 56]\n"
     ]
    }
   ],
   "source": [
    "print(len(final_test_df) + len(station_dfs[0]) + len(station_dfs[1]) + len(station_dfs[2]) + len(station_dfs[3]) + len(station_dfs[4]) + len(station_dfs[5]))\n",
    "print(len(df_data))\n",
    "print(len(final_test_df))\n",
    "print([len(station_dfs[idx]) for idx in range(len(station_dfs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2181f28",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056816fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 21\n",
      "35 21\n",
      "35 21\n",
      "35 21\n",
      "39 22\n",
      "35 21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure()\n",
    "sns.countplot(x=\"label\", data=final_test_df, palette='rocket');\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for idx in range(len(station_dfs)):\n",
    "    plt.subplot(1,6,idx+1)\n",
    "    B, M = station_dfs[idx][\"label\"].value_counts()\n",
    "    print(B, M)\n",
    "    sns.countplot(x=\"label\", data=station_dfs[idx], palette='rocket');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e73a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "              'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "              'concave.points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "              'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "              'compactness_se', 'concavity_se', 'concave.points_se', 'symmetry_se',\n",
    "              'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "              'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "              'compactness_worst', 'concavity_worst', 'concave.points_worst',\n",
    "              'symmetry_worst', 'fractal_dimension_worst']\n",
    "Y_FEATURE = 'label'\n",
    "df_mean_X = []\n",
    "df_std_X = []\n",
    "\n",
    "for idx in range(len(station_list)):\n",
    "    df_mean_X.append(np.mean(station_dfs[idx][X_FEATURES], axis=0).to_numpy())\n",
    "    df_std_X.append(np.std(station_dfs[idx][X_FEATURES], axis=0).to_numpy())\n",
    "\n",
    "df_mean_X.append(np.mean(final_test_df[X_FEATURES], axis=0).to_numpy())\n",
    "df_std_X.append(np.std(final_test_df[X_FEATURES], axis=0).to_numpy())\n",
    "df_mean_X = pd.DataFrame(df_mean_X, columns=X_FEATURES)\n",
    "df_std_X = pd.DataFrame(df_std_X, columns=X_FEATURES)\n",
    "df_mean_X[\"station\"] = pd.Series(station_list+[\"final test\"])\n",
    "df_std_X[\"station\"] = pd.Series(station_list+[\"final test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a51f21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave.points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave.points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.731571</td>\n",
       "      <td>19.582857</td>\n",
       "      <td>89.354107</td>\n",
       "      <td>608.767857</td>\n",
       "      <td>0.094890</td>\n",
       "      <td>0.104666</td>\n",
       "      <td>0.082391</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.177461</td>\n",
       "      <td>0.063306</td>\n",
       "      <td>...</td>\n",
       "      <td>26.149643</td>\n",
       "      <td>103.899643</td>\n",
       "      <td>812.069643</td>\n",
       "      <td>0.133315</td>\n",
       "      <td>0.269866</td>\n",
       "      <td>0.269384</td>\n",
       "      <td>0.113831</td>\n",
       "      <td>0.276321</td>\n",
       "      <td>0.086851</td>\n",
       "      <td>uka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.397768</td>\n",
       "      <td>18.889821</td>\n",
       "      <td>93.583929</td>\n",
       "      <td>671.785714</td>\n",
       "      <td>0.096442</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.088604</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>0.180682</td>\n",
       "      <td>0.062323</td>\n",
       "      <td>...</td>\n",
       "      <td>25.928929</td>\n",
       "      <td>109.231786</td>\n",
       "      <td>907.616071</td>\n",
       "      <td>0.135511</td>\n",
       "      <td>0.269095</td>\n",
       "      <td>0.296277</td>\n",
       "      <td>0.122032</td>\n",
       "      <td>0.293105</td>\n",
       "      <td>0.085412</td>\n",
       "      <td>ukg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.210804</td>\n",
       "      <td>19.831964</td>\n",
       "      <td>92.376071</td>\n",
       "      <td>662.580357</td>\n",
       "      <td>0.094050</td>\n",
       "      <td>0.098760</td>\n",
       "      <td>0.077473</td>\n",
       "      <td>0.045377</td>\n",
       "      <td>0.178232</td>\n",
       "      <td>0.062172</td>\n",
       "      <td>...</td>\n",
       "      <td>25.904821</td>\n",
       "      <td>108.191429</td>\n",
       "      <td>883.089286</td>\n",
       "      <td>0.125765</td>\n",
       "      <td>0.231277</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.104961</td>\n",
       "      <td>0.277905</td>\n",
       "      <td>0.080141</td>\n",
       "      <td>ukk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.041125</td>\n",
       "      <td>19.713036</td>\n",
       "      <td>91.210000</td>\n",
       "      <td>648.178571</td>\n",
       "      <td>0.094190</td>\n",
       "      <td>0.100675</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>0.179416</td>\n",
       "      <td>0.062446</td>\n",
       "      <td>...</td>\n",
       "      <td>26.035893</td>\n",
       "      <td>106.121786</td>\n",
       "      <td>877.585714</td>\n",
       "      <td>0.128090</td>\n",
       "      <td>0.237016</td>\n",
       "      <td>0.238041</td>\n",
       "      <td>0.108172</td>\n",
       "      <td>0.283812</td>\n",
       "      <td>0.081378</td>\n",
       "      <td>ukl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.744197</td>\n",
       "      <td>18.907869</td>\n",
       "      <td>89.610820</td>\n",
       "      <td>617.924590</td>\n",
       "      <td>0.098141</td>\n",
       "      <td>0.106430</td>\n",
       "      <td>0.097691</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>...</td>\n",
       "      <td>25.281967</td>\n",
       "      <td>104.514426</td>\n",
       "      <td>821.937705</td>\n",
       "      <td>0.136072</td>\n",
       "      <td>0.253771</td>\n",
       "      <td>0.284095</td>\n",
       "      <td>0.120542</td>\n",
       "      <td>0.306526</td>\n",
       "      <td>0.087015</td>\n",
       "      <td>imise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean   area_mean  smoothness_mean  \\\n",
       "0    13.731571     19.582857       89.354107  608.767857         0.094890   \n",
       "1    14.397768     18.889821       93.583929  671.785714         0.096442   \n",
       "2    14.210804     19.831964       92.376071  662.580357         0.094050   \n",
       "3    14.041125     19.713036       91.210000  648.178571         0.094190   \n",
       "4    13.744197     18.907869       89.610820  617.924590         0.098141   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave.points_mean  symmetry_mean  \\\n",
       "0          0.104666        0.082391             0.045645       0.177461   \n",
       "1          0.104018        0.088604             0.049828       0.180682   \n",
       "2          0.098760        0.077473             0.045377       0.178232   \n",
       "3          0.100675        0.080000             0.045794       0.179416   \n",
       "4          0.106430        0.097691             0.052405       0.185074   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                0.063306  ...      26.149643       103.899643  812.069643   \n",
       "1                0.062323  ...      25.928929       109.231786  907.616071   \n",
       "2                0.062172  ...      25.904821       108.191429  883.089286   \n",
       "3                0.062446  ...      26.035893       106.121786  877.585714   \n",
       "4                0.064454  ...      25.281967       104.514426  821.937705   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave.points_worst  \\\n",
       "0          0.133315           0.269866         0.269384              0.113831   \n",
       "1          0.135511           0.269095         0.296277              0.122032   \n",
       "2          0.125765           0.231277         0.229873              0.104961   \n",
       "3          0.128090           0.237016         0.238041              0.108172   \n",
       "4          0.136072           0.253771         0.284095              0.120542   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  station  \n",
       "0        0.276321                 0.086851      uka  \n",
       "1        0.293105                 0.085412      ukg  \n",
       "2        0.277905                 0.080141      ukk  \n",
       "3        0.283812                 0.081378      ukl  \n",
       "4        0.306526                 0.087015    imise  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd93ff84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave.points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave.points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.926020</td>\n",
       "      <td>4.843530</td>\n",
       "      <td>20.201886</td>\n",
       "      <td>277.122168</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.060492</td>\n",
       "      <td>0.070533</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>0.026809</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>...</td>\n",
       "      <td>7.397978</td>\n",
       "      <td>28.650615</td>\n",
       "      <td>450.418996</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>0.192328</td>\n",
       "      <td>0.207938</td>\n",
       "      <td>0.066242</td>\n",
       "      <td>0.046357</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>uka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.228776</td>\n",
       "      <td>4.378659</td>\n",
       "      <td>21.740257</td>\n",
       "      <td>314.734701</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>0.043006</td>\n",
       "      <td>0.066657</td>\n",
       "      <td>0.032307</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>...</td>\n",
       "      <td>6.753764</td>\n",
       "      <td>30.197674</td>\n",
       "      <td>522.003759</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>0.159774</td>\n",
       "      <td>0.206911</td>\n",
       "      <td>0.059225</td>\n",
       "      <td>0.056542</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>ukg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.526905</td>\n",
       "      <td>4.576257</td>\n",
       "      <td>24.442783</td>\n",
       "      <td>329.270842</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>...</td>\n",
       "      <td>6.148746</td>\n",
       "      <td>34.081328</td>\n",
       "      <td>507.822445</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.163689</td>\n",
       "      <td>0.198969</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.052208</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>ukk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.583369</td>\n",
       "      <td>4.815006</td>\n",
       "      <td>24.590153</td>\n",
       "      <td>348.758869</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.048429</td>\n",
       "      <td>0.067751</td>\n",
       "      <td>0.036131</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>...</td>\n",
       "      <td>6.378750</td>\n",
       "      <td>33.516174</td>\n",
       "      <td>587.667935</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>0.163827</td>\n",
       "      <td>0.059545</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>ukl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.348225</td>\n",
       "      <td>4.023645</td>\n",
       "      <td>23.147326</td>\n",
       "      <td>319.766652</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.047897</td>\n",
       "      <td>0.085303</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>...</td>\n",
       "      <td>5.833279</td>\n",
       "      <td>31.048951</td>\n",
       "      <td>499.600696</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.137068</td>\n",
       "      <td>0.192088</td>\n",
       "      <td>0.062331</td>\n",
       "      <td>0.075538</td>\n",
       "      <td>0.017028</td>\n",
       "      <td>imise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean   area_mean  smoothness_mean  \\\n",
       "0     2.926020      4.843530       20.201886  277.122168         0.014855   \n",
       "1     3.228776      4.378659       21.740257  314.734701         0.013174   \n",
       "2     3.526905      4.576257       24.442783  329.270842         0.013011   \n",
       "3     3.583369      4.815006       24.590153  348.758869         0.012611   \n",
       "4     3.348225      4.023645       23.147326  319.766652         0.012573   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave.points_mean  symmetry_mean  \\\n",
       "0          0.060492        0.070533             0.033302       0.026809   \n",
       "1          0.043006        0.066657             0.032307       0.020013   \n",
       "2          0.052094        0.075330             0.039270       0.025404   \n",
       "3          0.048429        0.067751             0.036131       0.027967   \n",
       "4          0.047897        0.085303             0.038901       0.029158   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                0.007918  ...       7.397978        28.650615  450.418996   \n",
       "1                0.006693  ...       6.753764        30.197674  522.003759   \n",
       "2                0.005878  ...       6.148746        34.081328  507.822445   \n",
       "3                0.007328  ...       6.378750        33.516174  587.667935   \n",
       "4                0.007371  ...       5.833279        31.048951  499.600696   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave.points_worst  \\\n",
       "0          0.027678           0.192328         0.207938              0.066242   \n",
       "1          0.023050           0.159774         0.206911              0.059225   \n",
       "2          0.018150           0.163689         0.198969              0.068884   \n",
       "3          0.018573           0.132725         0.163827              0.059545   \n",
       "4          0.021545           0.137068         0.192088              0.062331   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  station  \n",
       "0        0.046357                 0.019563      uka  \n",
       "1        0.056542                 0.021350      ukg  \n",
       "2        0.052208                 0.013139      ukk  \n",
       "3        0.046832                 0.015148      ukl  \n",
       "4        0.075538                 0.017028    imise  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a74dc",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be60f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.output_layer(self.sigmoid(self.hidden_layer(x)))\n",
    "        return out\n",
    "\n",
    "def train(X_train, y_train, model, criterion, optimizer):\n",
    "    inputs = torch.from_numpy(X_train).float()\n",
    "    targets = torch.from_numpy(y_train).long()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def valid(X_test, y_test, model, criterion):\n",
    "    inputs = torch.from_numpy(X_test).float()\n",
    "    targets = torch.from_numpy(y_test).long()\n",
    "    outputs = model(inputs)\n",
    "    val_loss = criterion(outputs, targets)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    cm = confusion_matrix(targets.numpy(), predicted.numpy())\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        val_acc = (tp + tn) / (tp + fp + fn + tn)\n",
    "        val_precesion = tp / (tp + fp)\n",
    "        val_recall = tp / (tp + fn)\n",
    "        val_f1_score = 2 * tp / (2 * tp + fn + fp)\n",
    "    return val_loss.item(), val_acc, val_precesion, val_recall, val_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b054edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 62) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 62), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (None, 62).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 62) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 62), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (None, 62).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 62) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 62), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (128, 62).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 62) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 62), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (128, 62).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 62) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 62), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (128, 62).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 62) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 62), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (128, 62).\n",
      "1000 [D loss: 0.639856 , acc: 51.56] [G loss: 0.769561]\n",
      "2000 [D loss: 0.619099 , acc: 81.25] [G loss: 0.722910]\n",
      "3000 [D loss: 0.679517 , acc: 57.42] [G loss: 0.682456]\n",
      "4000 [D loss: 0.667364 , acc: 50.00] [G loss: 0.756130]\n",
      "5000 [D loss: 0.712443 , acc: 42.19] [G loss: 0.735056]\n",
      "1000 [D loss: 0.685638 , acc: 65.62] [G loss: 0.736332]\n",
      "2000 [D loss: 0.649474 , acc: 80.08] [G loss: 0.787727]\n",
      "3000 [D loss: 0.729734 , acc: 40.23] [G loss: 0.757123]\n",
      "4000 [D loss: 0.701587 , acc: 47.27] [G loss: 0.696685]\n",
      "5000 [D loss: 0.635782 , acc: 82.81] [G loss: 0.774419]\n",
      "1000 [D loss: 0.673077 , acc: 63.67] [G loss: 0.786606]\n",
      "2000 [D loss: 0.651121 , acc: 72.27] [G loss: 0.862317]\n",
      "3000 [D loss: 0.726471 , acc: 40.62] [G loss: 0.695188]\n",
      "4000 [D loss: 0.703773 , acc: 53.12] [G loss: 0.754092]\n",
      "5000 [D loss: 0.684767 , acc: 44.14] [G loss: 0.679705]\n",
      "1000 [D loss: 0.680953 , acc: 63.67] [G loss: 0.712149]\n",
      "2000 [D loss: 0.725556 , acc: 41.41] [G loss: 0.751865]\n",
      "3000 [D loss: 0.685712 , acc: 57.03] [G loss: 0.713850]\n",
      "4000 [D loss: 0.674401 , acc: 61.72] [G loss: 0.695489]\n",
      "5000 [D loss: 0.690542 , acc: 44.14] [G loss: 0.667536]\n",
      "1000 [D loss: 0.676161 , acc: 53.91] [G loss: 0.672825]\n",
      "2000 [D loss: 0.644416 , acc: 84.38] [G loss: 0.746569]\n",
      "3000 [D loss: 0.688019 , acc: 59.38] [G loss: 0.753882]\n",
      "4000 [D loss: 0.731173 , acc: 12.89] [G loss: 0.673198]\n",
      "5000 [D loss: 0.726017 , acc: 50.00] [G loss: 0.669288]\n",
      "1000 [D loss: 0.683282 , acc: 66.02] [G loss: 0.684584]\n",
      "2000 [D loss: 0.709154 , acc: 42.19] [G loss: 0.679550]\n",
      "3000 [D loss: 0.660468 , acc: 72.27] [G loss: 0.719962]\n",
      "4000 [D loss: 0.684414 , acc: 61.72] [G loss: 0.735501]\n",
      "5000 [D loss: 0.668181 , acc: 75.39] [G loss: 0.705602]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "iteration_checks = []\n",
    "\n",
    "def shuffle_list(lst):\n",
    "    lst2 = lst.copy()\n",
    "    random.shuffle(lst2)\n",
    "    return lst2\n",
    "\n",
    "\n",
    "def train_synthetic(data, iterations, batch_size, interval, number_of_row):\n",
    "    Xtrainnew = data\n",
    "    mydata = Xtrainnew.values.tolist()\n",
    "    ytrain = []\n",
    "    for j in mydata:\n",
    "        ytrain.append(j[0])\n",
    "    Xtrainnew = pd.DataFrame(data=mydata)\n",
    "    Ytrainnew = np.array(ytrain)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(Xtrainnew)\n",
    "    Xtrain = scaled\n",
    "    ytrain = Ytrainnew\n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        ids = np.random.randint(0, Xtrain.shape[0], batch_size)\n",
    "        imgs = Xtrain[ids]\n",
    "        labels = ytrain[ids]\n",
    "\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = gen_v.predict([z, labels])\n",
    "\n",
    "        dloss_real = dis_v.train_on_batch([imgs, labels], real)\n",
    "        dloss_fake = dis_v.train_on_batch([gen_imgs, labels], fake)\n",
    "\n",
    "        dloss, accuracy = 0.5 * np.add(dloss_real, dloss_fake)\n",
    "\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "        gloss = gan_v.train_on_batch([z, labels], real)\n",
    "\n",
    "        if (iteration + 1) % interval == 0:\n",
    "            losses.append((dloss, gloss))\n",
    "            accuracies.append(100.0 * accuracy)\n",
    "            iteration_checks.append(iteration + 1)\n",
    "\n",
    "            print(\"%d [D loss: %f , acc: %.2f] [G loss: %f]\" %\n",
    "                  (iteration + 1, dloss, 100.0 * accuracy, gloss))\n",
    "    return show_data(gen_v, scaler, number_of_row)\n",
    "\n",
    "\n",
    "def savelist2csv(mynamefile, mylist):\n",
    "    with open('./' + mynamefile, 'w') as myfile:\n",
    "        wr = csv.writer(myfile, delimiter='\\n', quoting=csv.QUOTE_MINIMAL)\n",
    "        wr.writerow(mylist)\n",
    "\n",
    "\n",
    "def show_data(gen, scaler, number_of_rows):\n",
    "    z = np.random.normal(0, 1, (number_of_rows, 100))\n",
    "    labels = np.random.randint(2, size=number_of_rows)\n",
    "    gen_imgs = gen.predict([z, labels])\n",
    "    gen_imgs = scaler.inverse_transform(gen_imgs)\n",
    "    for index in range(0, number_of_rows):\n",
    "        gen_imgs[index] = np.around(gen_imgs[index], 4)\n",
    "        gen_imgs[index][0] = np.around(gen_imgs[index][0], 0)\n",
    "    return gen_imgs\n",
    "\n",
    "\n",
    "def build_gen(zdim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(31, input_dim=zdim))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1 * 31, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cgen(zdim):\n",
    "    z = Input(shape=(zdim,))\n",
    "    lable = Input(shape=(1,), dtype='int32')\n",
    "    lable_emb = Embedding(num_classes, zdim, input_length=1)(lable)\n",
    "    lable_emb = Flatten()(lable_emb)\n",
    "    joined_rep = Multiply()([z, lable_emb])\n",
    "    gen_v = build_gen(zdim)\n",
    "    c_img = gen_v(joined_rep)\n",
    "    return Model([z, lable], c_img)\n",
    "\n",
    "\n",
    "def build_dis(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(31))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cdis(img_shape):\n",
    "    img = Input(shape=(img_cols,))\n",
    "    lable = Input(shape=(1,), dtype='int32')\n",
    "    lable_emb = Embedding(num_classes, np.prod((31)), input_length=1)(lable)\n",
    "    lable_emb = Flatten()(lable_emb)\n",
    "    # lable_emb=Reshape(img_shape)(lable_emb)\n",
    "    concate_img = Concatenate(axis=-1)([img, lable_emb])\n",
    "    dis_v = build_dis((img_rows, img_cols * 2))\n",
    "    classification = dis_v(concate_img)\n",
    "    return Model([img, lable], classification)\n",
    "\n",
    "\n",
    "def build_cgan(genrator, discriminator):\n",
    "    z = Input(shape=(zdim,))\n",
    "    lable = Input(shape=(1,), dtype='int32')\n",
    "    f_img = genrator([z, lable])\n",
    "    classification = discriminator([f_img, lable])\n",
    "    model = Model([z, lable], classification)\n",
    "    return model\n",
    "\n",
    "img_rows = 1\n",
    "img_cols = 31\n",
    "img_shape = (img_rows, img_cols)\n",
    "zdim = 100\n",
    "num_classes = 2\n",
    "dis_v = build_cdis(img_shape)\n",
    "dis_v.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "gen_v = build_cgen(zdim)\n",
    "dis_v.trainable = False\n",
    "gan_v = build_cgan(gen_v, dis_v)\n",
    "gan_v.compile(loss='binary_crossentropy',optimizer=Adam())\n",
    "\n",
    "def generation_synthetic_data(data):\n",
    "    labels_training = data[Y_FEATURE]\n",
    "    labels_training = labels_training.map(dict(M=1, B=0))\n",
    "    features_training = data[X_FEATURES]\n",
    "    # merge the data to one dataframe again for the training of cGAN\n",
    "    train_data_synthetic = pd.concat([labels_training, features_training], axis=1, join='inner')\n",
    "    # main method of the training of the cGAN as explained above\n",
    "    synthetic_data = train_synthetic(data=train_data_synthetic, iterations=5000, batch_size=128, interval=1000,\n",
    "                                     number_of_row=data.shape[1])\n",
    "    # the random generation for the patient-id, gender and birthday\n",
    "    # label needs to be transformed to the original values\n",
    "    label_synthetic = []\n",
    "    patient_id_synthetic = []\n",
    "    patient_gender_synthetic = []\n",
    "    patient_birthday_synthetic = []\n",
    "\n",
    "    # very simple approach for the missing data generation, note: can be improved\n",
    "    for row in range(0, len(synthetic_data)):\n",
    "        synthetic_data_row = synthetic_data[row,]\n",
    "        if (synthetic_data_row[0] == 1):\n",
    "            label_synthetic.append(\"M\")\n",
    "        else:\n",
    "            label_synthetic.append(\"B\")\n",
    "        patient_id_synthetic.append((\"bbmri\" + str(row)))\n",
    "        p_g = \"female\"\n",
    "        p_b = \"01.01.2000\"\n",
    "        patient_birthday_synthetic.append(p_b)\n",
    "        patient_gender_synthetic.append(p_g)\n",
    "\n",
    "    # use the X_FEATURES of the synthetic data\n",
    "    synthetic_data = synthetic_data[:, 1:31]\n",
    "\n",
    "    # write everything in a dataframe for representation\n",
    "    synthetic_df = pd.DataFrame(np.c_[\n",
    "                                    patient_id_synthetic, patient_gender_synthetic, patient_birthday_synthetic, synthetic_data, label_synthetic],\n",
    "                                columns=[\"patient_id\", \"gender\", \"birthDate\", \"radius_mean\", \"texture_mean\",\n",
    "                                         \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\",\n",
    "                                         \"concavity_mean\", \"concave.points_mean\", \"symmetry_mean\",\n",
    "                                         \"fractal_dimension_mean\",\n",
    "                                         \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\",\n",
    "                                         \"compactness_se\", \"concavity_se\", \"concave.points_se\", \"symmetry_se\",\n",
    "                                         \"fractal_dimension_se\", \"radius_worst\", \"texture_worst\", \"perimeter_worst\",\n",
    "                                         \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\",\n",
    "                                         \"concave.points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\", \"label\"])\n",
    "    return synthetic_df\n",
    "\n",
    "synthetic_dfs =  [generation_synthetic_data(station_dfs[idx]) for idx in range(len(station_list))] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f63f4",
   "metadata": {},
   "source": [
    "## Prepare Final Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091921e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler = StandardScaler()\n",
    "X_test = final_test_df[X_FEATURES]\n",
    "y_test = final_test_df[Y_FEATURE]\n",
    "X_test = test_scaler.fit_transform(X_test)\n",
    "y_test.replace(to_replace=dict(M=1, B=0), inplace=True)\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3d359",
   "metadata": {},
   "source": [
    "## Single Site Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fe2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 30\n",
    "hidden_dim = 64\n",
    "num_classes = 2\n",
    "\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.0005\n",
    "num_epochs = 600\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for idx in range(len(station_list)):\n",
    "    synthetic\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df_X = station_dfs[idx][X_FEATURES]\n",
    "    df_Y = station_dfs[idx][Y_FEATURE]\n",
    "    df_X = scaler.fit_transform(df_X)\n",
    "    df_Y.replace(to_replace=dict(M=1, B=0), inplace=True)\n",
    "    df_Y = df_Y.to_numpy()\n",
    "    _, X_val, _, y_val = train_test_split(df_X, df_Y, test_size=0.4, random_state=42)\n",
    "    \n",
    "    X_train = synthetic_dfs[idx][X_FEATURES]\n",
    "    y_train = synthetic_dfs[idx][Y_FEATURE]\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    y_train.replace(to_replace=dict(M=1, B=0), inplace=True)\n",
    "    y_train = y_train.to_numpy()\n",
    "    \n",
    "    model = LogisticRegression(input_dim, hidden_dim, num_classes)\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_precs = []\n",
    "    val_recs = []\n",
    "    val_f1s = []\n",
    "    for epoch in range(num_epochs):\n",
    "        perm = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(perm)\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "        loss = train(X_train, y_train, model, criterion, optim)\n",
    "        val_loss, val_acc, val_precesion, val_recall, val_f1_score = valid(X_val, y_val, model, criterion)\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_precs.append(val_precesion)\n",
    "        val_recs.append(val_recall)\n",
    "        val_f1s.append(val_f1_score)\n",
    "    test_loss, test_acc, test_precesion, test_recall, test_f1_score = valid(X_test, y_test, model, criterion)\n",
    "    plt.figure()\n",
    "    plt.plot(losses, label=\"train_loss\")\n",
    "    plt.plot(val_losses, label=\"val_loss\")\n",
    "    plt.plot(val_accs, label=\"val_acc\")\n",
    "    plt.plot(val_precs, label=\"val_prec\")\n",
    "    plt.plot(val_recs, label=\"val_rec\")\n",
    "    plt.plot(val_f1s, label=\"val_f1\")\n",
    "    plt.legend(title=\"Metrics\", loc=\"lower right\")\n",
    "    plt.title(\"single site training on {}\".format(station_list[idx].upper())),\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.xlabel(\"Performance\")\n",
    "    plt.show()\n",
    "    print(\"single site training on {}\".format(station_list[idx].upper()))\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"test_acc\", test_acc)\n",
    "    print(\"test_prec\", test_precesion)\n",
    "    print(\"test_rec\", test_recall)\n",
    "    print(\"test_f1\", test_f1_score)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae7a72",
   "metadata": {},
   "source": [
    "## Institutional Incremental Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ba620",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 30\n",
    "hidden_dim = 64\n",
    "num_classes = 2\n",
    "\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.0005\n",
    "num_epochs = 100\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = LogisticRegression(input_dim, hidden_dim, num_classes)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_precs = []\n",
    "val_recs = []\n",
    "val_f1s = []\n",
    "for idx in range(len(station_list)):\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scaler = StandardScaler()\n",
    "    df_X = station_dfs[idx][X_FEATURES]\n",
    "    df_Y = station_dfs[idx][Y_FEATURE]\n",
    "    df_X = scaler.fit_transform(df_X)\n",
    "    df_Y.replace(to_replace=dict(M=1, B=0), inplace=True)\n",
    "    df_Y = df_Y.to_numpy()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_X, df_Y, test_size=0.4, random_state=42)\n",
    "    for epoch in range(num_epochs):\n",
    "        perm = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(perm)\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "        loss = train(X_train, y_train, model, criterion, optim)\n",
    "        val_loss, val_acc, val_precesion, val_recall, val_f1_score = valid(X_val, y_val, model, criterion)\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_precs.append(val_precesion)\n",
    "        val_recs.append(val_recall)\n",
    "        val_f1s.append(val_f1_score)\n",
    "\n",
    "test_loss, test_acc, test_precesion, test_recall, test_f1_score = valid(X_test, y_test, model, criterion)    \n",
    "plt.figure()\n",
    "plt.plot(losses, label=\"train_loss\")\n",
    "plt.plot(val_losses, label=\"val_loss\")\n",
    "plt.plot(val_accs, label=\"val_acc\")\n",
    "plt.plot(val_precs, label=\"val_prec\")\n",
    "plt.plot(val_recs, label=\"val_rec\")\n",
    "plt.plot(val_f1s, label=\"val_f1\")\n",
    "plt.legend(title=\"Metrics\", loc=\"lower right\")\n",
    "plt.title(\"institutional incremental learning\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.xlabel(\"Performance\")\n",
    "plt.show()\n",
    "print(\"institutional incremental learning\")\n",
    "print(\"test loss\", test_loss)\n",
    "print(\"test_acc\", test_acc)\n",
    "print(\"test_prec\", test_precesion)\n",
    "print(\"test_rec\", test_recall)\n",
    "print(\"test_f1\", test_f1_score)\n",
    "print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7dd54c",
   "metadata": {},
   "source": [
    "## Cyclic Institutional Increamental Learning (CIIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 30\n",
    "hidden_dim = 64\n",
    "num_classes = 2\n",
    "\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.0005\n",
    "num_cycles = 10\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = LogisticRegression(input_dim, hidden_dim, num_classes)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_precs = []\n",
    "val_recs = []\n",
    "val_f1s = []\n",
    "for cycle in range(num_cycles):\n",
    "    for idx in range(len(station_list)):\n",
    "        optim = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scaler = StandardScaler()\n",
    "        df_X = station_dfs[idx][X_FEATURES]\n",
    "        df_Y = station_dfs[idx][Y_FEATURE]\n",
    "        df_X = scaler.fit_transform(df_X)\n",
    "        df_Y.replace(to_replace=dict(M=1, B=0), inplace=True)\n",
    "        df_Y = df_Y.to_numpy()\n",
    "        X_train, X_val, y_train, y_val = train_test_split(df_X, df_Y, test_size=0.4, random_state=42)\n",
    "        for epoch in range(num_epochs):\n",
    "            perm = np.arange(X_train.shape[0])\n",
    "            np.random.shuffle(perm)\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            loss = train(X_train, y_train, model, criterion, optim)\n",
    "            val_loss, val_acc, val_precesion, val_recall, val_f1_score = valid(X_val, y_val, model, criterion)\n",
    "            losses.append(loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            val_precs.append(val_precesion)\n",
    "            val_recs.append(val_recall)\n",
    "            val_f1s.append(val_f1_score)\n",
    "\n",
    "test_loss, test_acc, test_precesion, test_recall, test_f1_score = valid(X_test, y_test, model, criterion)    \n",
    "plt.figure()\n",
    "plt.plot(losses, label=\"train_loss\")\n",
    "plt.plot(val_losses, label=\"val_loss\")\n",
    "plt.plot(val_accs, label=\"val_acc\")\n",
    "plt.plot(val_precs, label=\"val_prec\")\n",
    "plt.plot(val_recs, label=\"val_rec\")\n",
    "plt.plot(val_f1s, label=\"val_f1\")\n",
    "plt.legend(title=\"Metrics\", loc=\"lower right\")\n",
    "plt.title(\"cyclic institutional incremental learning\"),\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.xlabel(\"Performance\")\n",
    "plt.show()\n",
    "print(\"cyclic institutional incremental learning\")\n",
    "print(\"test loss\", test_loss)\n",
    "print(\"test_acc\", test_acc)\n",
    "print(\"test_prec\", test_precesion)\n",
    "print(\"test_rec\", test_recall)\n",
    "print(\"test_f1\", test_f1_score)\n",
    "print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044f992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
